{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "slide_type": "subslide"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Diagonalization\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<center>\n",
    "<img src=\"images/PottermoreDiagonAlley1.jpg\" alt=\"Diagon Alley\" width=\"450\">\n",
    "<br>\n",
    "\"Welcome, Harry, to Diagon Alley\"\n",
    "<P>\n",
    "<center>\n",
    "   -- Rubeus Hagrid\n",
    "</center>\n",
    "\n",
    "<div style=\"visibility: hidden\"> \n",
    "Source:\n",
    "http://img3.wikia.nocookie.net/__cb20140714004320/harrypotter/images/8/84/PottermoreDiagonAlley1.jpg\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "internals": {},
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "# import libraries\n",
    "import numpy as np\n",
    "import matplotlib as mp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import laUtilities as ut\n",
    "import slideUtilities as sl\n",
    "import demoUtilities as dm\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from IPython.display import Image\n",
    "from IPython.display import display_html\n",
    "from IPython.display import display\n",
    "from IPython.display import Math\n",
    "from IPython.display import Latex\n",
    "from IPython.display import HTML\n",
    "reload(dm)\n",
    "reload(ut)\n",
    "reload(sl)\n",
    "print ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "internals": {},
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       " .container.slides .celltoolbar, .container.slides .hide-in-slideshow {\n",
       "    display: None ! important;\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    " .container.slides .celltoolbar, .container.slides .hide-in-slideshow {\n",
    "    display: None ! important;\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {},
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "%Set up useful MathJax (Latex) macros.\n",
    "%See http://docs.mathjax.org/en/latest/tex.html#defining-tex-macros\n",
    "%These are for use in the slideshow\n",
    "$\\newcommand{\\mat}[1]{\\left[\\begin{array}#1\\end{array}\\right]}$\n",
    "$\\newcommand{\\vx}{{\\mathbf x}}$\n",
    "$\\newcommand{\\R}{{\\mathbb{R}}}$\n",
    "$\\newcommand{\\vu}{{\\mathbf u}}$\n",
    "$\\newcommand{\\vv}{{\\mathbf v}}$\n",
    "$\\newcommand{\\col}{{\\operatorname{Col}}}$\n",
    "$\\newcommand{\\nul}{{\\operatorname{Nul}}}$\n",
    "$\\newcommand{\\vb}{{\\mathbf b}}$\n",
    "$\\newcommand{\\va}{{\\mathbf a}}$\n",
    "$\\newcommand{\\ve}{{\\mathbf e}}$\n",
    "$\\newcommand{\\setb}{{\\mathcal{B}}}$\n",
    "$\\newcommand{\\rank}{{\\operatorname{rank}}}$"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "internals": {
     "slide_helper": "subslide_end"
    },
    "slide_helper": "slide_end",
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "\\newcommand{\\mat}[1]{\\left[\\begin{array}#1\\end{array}\\right]}\n",
    "\\newcommand{\\vx}{{\\mathbf x}}\n",
    "\\newcommand{\\vb}{{\\mathbf b}}\n",
    "\\newcommand{\\vu}{{\\mathbf u}}\n",
    "\\newcommand{\\vv}{{\\mathbf v}}\n",
    "\\newcommand{\\va}{{\\mathbf a}}\n",
    "\\newcommand{\\ve}{{\\mathbf e}}\n",
    "\\newcommand{\\R}{{\\mathbb{R}}}\n",
    "\\newcommand{\\col}{{\\operatorname{Col}}}\n",
    "\\newcommand{\\nul}{{\\operatorname{Nul}}}\n",
    "\\newcommand{\\rank}{{\\operatorname{rank}}}\n",
    "\\newcommand{\\setb}{{\\mathcal{B}}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Today we consider an important factorization of a square matrix.   \n",
    "\n",
    "This factorization uses eigenvalues and eigenvectors, and makes may problems substantially easier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The factorization is of the form $A = PDP^{-1},$ where $D$ is a diagonal matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "This factorization allows us to compute $A^k$ quickly for large values of $k,$ which is fundamental to many problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Here is an example of why we'd like to do such a thing:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Example.__  Consider taking the powers of a diagonal matrix.  For example, $D = \\mat{{rr}5&0\\\\0&3}.$  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Then note that $D^2 = \\mat{{rr}5&0\\\\0&3}\\mat{{rr}5&0\\\\0&3} = \\mat{{cc}5^2&0\\\\0&3^2},$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "And $D^3 = DD^2 = \\mat{{rr}5&0\\\\0&3}\\mat{{cc}5^2&0\\\\0&3^2} = \\mat{{cc}5^3&0\\\\0&3^3}.$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "So in general,\n",
    "\n",
    "$$ D^k = \\mat{{rr}5^k&0\\\\0&3^k} \\;\\;\\;\\mbox{for}\\;k\\geq1.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__Extending this to a general matrix $A$.__\n",
    "\n",
    "Now, consider if $A$ is __similar__ to a diagonal matrix.  For example, let $A = PDP^{-1}$ for some invertible $P$ and diagonal $D$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Then, $A^k$ is also easy to compute.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "__Example.__ Let $A = \\mat{{rr}7&2\\\\-4&1}.$  Find a formula for $A^k,$ given that $A = PDP^{-1},$ where\n",
    "\n",
    "$$P = \\mat{{cc}1&1\\\\-1&-2}\\;\\mbox{and}\\;D = \\mat{{cc}5&0\\\\0&3}$$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "__Solution.__   \n",
    "\n",
    "The standard formula for the inverse of a $2\\times 2$ matrix yields\n",
    "\n",
    "$$P^{-1} = \\mat{{cc}2&1\\\\-1&-1}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Then, by associativity of matrix multiplication,\n",
    "\n",
    "$$A^2 = (PDP^{-1})(PDP^{-1}) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$= PD(P^{-1}P)DP^{-1}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$ = PDDP^{-1}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$ = PD^2P^{-1}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$ = \\mat{{rr}1&1\\\\-1&-2}\\mat{{rr}5^2&0\\\\0&3^2}\\mat{{rr}2&1\\\\-1&-1}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In general, for $k\\geq 1,$\n",
    "\n",
    "$$A^k = PD^kP^{-1}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$=\\mat{{rr}1&1\\\\-1&-2}\\mat{{rr}5^k&0\\\\0&3^k}\\mat{{rr}2&1\\\\-1&-1}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$=\\mat{{rr}2\\cdot5^k-3^k&5^k-3^k\\\\2\\cdot3^k-2\\cdot5^k&2\\cdot3^k-5^k}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "A square matrix $A$ is said to be __diagonalizable__ if $A$ is similar to a diagonal matrix, that is, if $A = PDP^{-1},$ for some invertible matrix $P$ and some diagonal matrix $D$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Next we will show that to diagonalize a matrix, one __must__ use the eigenvectors and eigenvalues of $A$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "__Theorem.__ (The Diagonalization Theorem)\n",
    "\n",
    "An $n\\times n$ matrix $A$ is diagonalizable if and only if $A$ has $n$ linearly independent eigenvectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In fact, $A = PDP^{-1},$ with $D$ a diagonal matrix, if and only if the columns of $P$ are $n$ linearly independent eigenvectors of $A.$  \n",
    "\n",
    "In this case, the diagonal entires of $D$ are eigenvalues of $A$ that correspond, respectively, to the eigenvectors in $P$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    " In other words, $A$ is diagonalizable if and only if there are enough eigenvectors to form a basis of $\\R^n$.  We call such a basis an __eigevector basis__ or an __eigenbasis__ of $\\R^n$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "__Proof.__\n",
    "\n",
    "First, observe that if $P$ is any $n\\times n$ matrix with columns $\\vv_1,\\dots,\\vv_n,$ and if $D$ is any diagonal matrix with diagonal entries $\\lambda_1,\\dots,\\lambda_n,$ then\n",
    "\n",
    "$$AP = A[\\vv_1\\;\\vv_2\\;\\cdots\\;\\vv_n] = [A\\vv_1\\;A\\vv_2\\;\\cdots\\;A\\vv_n]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "while\n",
    "\n",
    "$$PD = P\\mat{{cccc}\\lambda_1&0&\\cdots&0\\\\0&\\lambda_2&\\cdots&0\\\\\\vdots&\\vdots&\\ddots&\\vdots\\\\0&0&\\cdots&\\lambda_n} = [\\lambda_1\\vv_1\\;\\lambda_2\\vv_2\\;\\cdots\\;\\lambda_n\\vv_n].$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Now suppose $A$ is diagonalizable and $A = PDP^{-1}.$  Then right-multiplying this relation by P, we have \n",
    "\n",
    "$$AP = PD$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In this case, the calculations above show that\n",
    "\n",
    "$$[A\\vv_1\\;A\\vv_2\\;\\cdots\\;A\\vv_n] = [\\lambda_1\\vv_1\\;\\lambda_2\\vv_2\\;\\cdots\\;\\lambda_n\\vv_n].$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Equating columns, we find that\n",
    "\n",
    "$$A\\vv_1 = \\lambda_1\\vv_1, \\;\\;\\; A\\vv_2 = \\lambda_2\\vv_2, \\;\\;\\; \\dots, \\;\\;\\; A\\vv_n = \\lambda_n\\vv_n$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Since $P$ is invertible, its columns $\\vv_1, \\dots,\\vv_n$ must be linearly independent.  Also, since these columns are nonzero, the equations above show that $\\lambda_1, \\dots, \\lambda_n$ are eigenvalues and $\\vv_1, \\dots, \\vv_n$ are the corresponding eigenvectors.  \n",
    "\n",
    "This proves the \"only if\" part of the theorem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "To prove the \"if\" part of the theorem is straightforward:  given an $n$ eigenvectors $\\vv_1,\\dots,\\vv_n,$ use them to construct the columns of $P$ and use corresponding eigenvalues $\\lambda_1, \\dots, \\lambda_n$ to construct $D$.  \n",
    "\n",
    "Using the sequence of equations above in reverse order, we can go from \n",
    "\n",
    "$$A\\vv_1 = \\lambda_1\\vv_1, \\;\\;\\; A\\vv_2 = \\lambda_2\\vv_2, \\;\\;\\; \\dots, \\;\\;\\; A\\vv_n = \\lambda_n\\vv_n$$\n",
    "\n",
    "to \n",
    "\n",
    "$$AP = PD.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Since the eigenvectors are given as linearly idenpendent, $P$ is invertible and so \n",
    "\n",
    "$$A = PDP^{-1}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The takeaway is this:\n",
    "\n",
    "Every $n\\times n$ matrix having $n$ linearly independent eigenvectors can be factored into the product of a matrix $P$, a diagonal matrix $D$, and the inverse of $P$ - where $P$ holds the eigenvectors of $A$, and $D$ holds the eigenvalues of $A$.\n",
    "\n",
    "This is the __eigendecomposition__ of $A$.   \n",
    "\n",
    "(It is quite fundamental!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Diagonalizing a Matrix\n",
    "\n",
    "Let's put this all together and see how to diagonalize a matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "__Example.__  Diagonalize the following matrix, if possible.\n",
    "\n",
    "$$A = \\mat{{rrr}1&3&3\\\\-3&-5&-3\\\\3&3&1}$$\n",
    "\n",
    "That is, find an invertible matrix $P$ and a diagonal matrix $D$ such that $A = PDP^{-1}.$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "__Solution.__\n",
    "\n",
    "__Step 1: Find the eigenvalues of $A$.__\n",
    "\n",
    "This is routine for us now.  If we are working with $2\\times2$ matrices, we may choose to find the roots of the characteristic polynomial (quadratic).  For anything larger we'd use a computer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In this case, the characteristic equation turns out to involve a cubic polynomial that can be factored:\n",
    "\n",
    "$$0 = \\det(A-\\lambda I) $$\n",
    "\n",
    "$$ = -\\lambda^3 - 3\\lambda^2 + 4$$\n",
    "\n",
    "$$ = -(\\lambda -1)(\\lambda +2)^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "So the eigenvalues are $\\lambda = 1$ and $\\lambda = -2$ (with multiplicity two)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "__Step 2: Find three linearly independent eigenvectors of $A$.__\n",
    "\n",
    "Note that we need _three_ linearly independent vectors because $A$ is $3\\times3.$  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "This is the step at which, if $A$ cannot be diagonalized, we find out because we cannot form 3 independent eigenvectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Using our standard method (finding the nullspace of $A - \\lambda I$) we find a basis for each eigenspace:\n",
    "\n",
    "Basis for $\\lambda = 1$: $\\vv_1 = \\mat{{r}1\\\\-1\\\\1}.$\n",
    "\n",
    "Basis for $\\lambda = -2$: $\\vv_2 = \\mat{{r}-1\\\\1\\\\0}$ and $\\vv_3 = \\mat{{r}-1\\\\0\\\\1}.$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Check that $\\{\\vv_1, \\vv_2, \\vv_3\\}$ forms a linearly independent set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "__Step 3: Construct $P$ from the vectors in Step 2.__\n",
    "\n",
    "The order of the vectors is actually not important.\n",
    "\n",
    "$$P = [\\vv_1\\;\\vv_2\\;\\vv_3] = \\mat{{rrr}1&-1&-1\\\\-1&1&0\\\\1&0&1}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "__Step 4: Construct $D$ from the corresponding eigenvalues.__\n",
    "\n",
    "The order of eigenvalues must match the order of eigenvectors used in the previous step.\n",
    "\n",
    "If an eigenvalue has multiplicity greater than 1, then repeat it the corresponding number of times.\n",
    "\n",
    "$$D = \\mat{{rrr}1&0&0\\\\0&-2&0\\\\0&0&-2}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "And we are done.   We have diagonalized $A$:\n",
    "\n",
    "$$A =  \\mat{{rrr}1&3&3\\\\-3&-5&-3\\\\3&3&1} = \\mat{{rrr}1&-1&-1\\\\-1&1&0\\\\1&0&1}  \\mat{{rrr}1&0&0\\\\0&-2&0\\\\0&0&-2}\\mat{{rrr}1&-1&-1\\\\-1&1&0\\\\1&0&1}^{-1}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "So, just as a reminder, we can now take powers of $A$ quite efficiently:\n",
    "\n",
    "$$A^{100} = \\mat{{rrr}1&-1&-1\\\\-1&1&0\\\\1&0&1}  \\mat{{rrr}1^{100}&0&0\\\\0&(-2)^{100}&0\\\\0&0&(-2)^{100}}\\mat{{rrr}1&-1&-1\\\\-1&1&0\\\\1&0&1}^{-1}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__Example.__   Let's look at an example of how diagonalization can fail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Diagonalize the following matrix, if possible.\n",
    "\n",
    "$$A = \\mat{{rrr}2&4&3\\\\-4&-6&-3\\\\3&3&1}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "__Solution.__ The characteristic equation of $A$ turns out to be the same as in the last example:\n",
    "\n",
    "$$0 = \\det(A-\\lambda I) = -(\\lambda-1)(\\lambda +2)^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The eigenvalues are $\\lambda = 1$ and $\\lambda = -2.$  However, it is easy to verify that each eigenspace is only one-dimensional:\n",
    "\n",
    "Basis for $\\lambda_1 = 1$: $\\vv_1 = \\mat{{r}1\\\\-1\\\\1}.$\n",
    "\n",
    "Basis for $\\lambda_2 = -2$: $\\vv_2 = \\mat{{r}-1\\\\1\\\\0}.$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "There are not other eigenvalues, and every eigenvector of $A$ is a multiple of either $\\vv_1$ or $\\vv_2.$  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Hence it is impossible to construct a basis of $\\R^3$ using eigenvectors of $A$. \n",
    "\n",
    "So we conclude that $A$ is __not__ diagonalizable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__An Important Case.__\n",
    "\n",
    "There is an important situation in which we can conclude immediately that $A$ is diagonalizable, without explicitly constructing and testing the eigenspaces of $A$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "__Theorem.__\n",
    "\n",
    "An $n\\times n$ matrix with $n$ distinct eigenvalues is diagonalizable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "__Proof.__\n",
    "\n",
    "There is a straightforward proof in the book showing that any set of eigenvectors corresponding to distinct eigenvalues is linearly independent.   Using that fact here, we have $n$ linearly independent eigenvectors, so $A$ must be diagonalizable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "__Example.__\n",
    "\n",
    "Determine if the following matrix is diagonalizable.\n",
    "\n",
    "$$A = \\mat{{rrr}5&-8&1\\\\0&0&7\\\\0&0&-2}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "__Solution.__\n",
    "\n",
    "It's easy!  Since $A$ is triangular, its eigenvalues are $5, 0,$ and $-2$.  Since $A$ is a $3\\times3$ with 3 distinct eigenvalues, $A$ is diagonalizable."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
