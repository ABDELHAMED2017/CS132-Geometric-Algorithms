{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "slide_type": "subslide"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# PageRank\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<center>\n",
    "<img src=\"images/Page-et-Brin.jpeg\" alt=\"Larry Page and Sergey Brin\" width=\"450\">\n",
    "<br>\n",
    "Larry Page and Sergey Brin\n",
    "\n",
    "\n",
    "<div style=\"visibility: hidden\"> \n",
    "Source:\n",
    "http://pixshark.com/sergey-brin-and-larry-page.htm\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "internals": {},
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "# import libraries\n",
    "import numpy as np\n",
    "import matplotlib as mp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import laUtilities as ut\n",
    "import slideUtilities as sl\n",
    "import demoUtilities as dm\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from IPython.display import Image\n",
    "from IPython.display import display_html\n",
    "from IPython.display import display\n",
    "from IPython.display import Math\n",
    "from IPython.display import Latex\n",
    "from IPython.display import HTML\n",
    "reload(dm)\n",
    "reload(ut)\n",
    "reload(sl)\n",
    "print ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "internals": {},
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       " .container.slides .celltoolbar, .container.slides .hide-in-slideshow {\n",
       "    display: None ! important;\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    " .container.slides .celltoolbar, .container.slides .hide-in-slideshow {\n",
    "    display: None ! important;\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {},
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "%Set up useful MathJax (Latex) macros.\n",
    "%See http://docs.mathjax.org/en/latest/tex.html#defining-tex-macros\n",
    "%These are for use in the slideshow\n",
    "$\\newcommand{\\mat}[1]{\\left[\\begin{array}#1\\end{array}\\right]}$\n",
    "$\\newcommand{\\vx}{{\\mathbf x}}$\n",
    "$\\newcommand{\\R}{{\\mathbb{R}}}$\n",
    "$\\newcommand{\\vu}{{\\mathbf u}}$\n",
    "$\\newcommand{\\vv}{{\\mathbf v}}$\n",
    "$\\newcommand{\\col}{{\\operatorname{Col}}}$\n",
    "$\\newcommand{\\nul}{{\\operatorname{Nul}}}$\n",
    "$\\newcommand{\\vb}{{\\mathbf b}}$\n",
    "$\\newcommand{\\va}{{\\mathbf a}}$\n",
    "$\\newcommand{\\ve}{{\\mathbf e}}$\n",
    "$\\newcommand{\\setb}{{\\mathcal{B}}}$\n",
    "$\\newcommand{\\rank}{{\\operatorname{rank}}}$\n",
    "$\\newcommand{\\vp}{{\\mathbf p}}$"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "internals": {
     "slide_helper": "subslide_end"
    },
    "slide_helper": "slide_end",
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "\\newcommand{\\mat}[1]{\\left[\\begin{array}#1\\end{array}\\right]}\n",
    "\\newcommand{\\vx}{{\\mathbf x}}\n",
    "\\newcommand{\\vb}{{\\mathbf b}}\n",
    "\\newcommand{\\vu}{{\\mathbf u}}\n",
    "\\newcommand{\\vv}{{\\mathbf v}}\n",
    "\\newcommand{\\va}{{\\mathbf a}}\n",
    "\\newcommand{\\ve}{{\\mathbf e}}\n",
    "\\newcommand{\\vp}{{\\mathbf p}}\n",
    "\\newcommand{\\R}{{\\mathbb{R}}}\n",
    "\\newcommand{\\col}{{\\operatorname{Col}}}\n",
    "\\newcommand{\\nul}{{\\operatorname{Nul}}}\n",
    "\\newcommand{\\rank}{{\\operatorname{rank}}}\n",
    "\\newcommand{\\setb}{{\\mathcal{B}}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Today we'll study an algorithm that is probably important in your life: Google's PageRank."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "By way of history: the World Wide Web starting becoming widely used in 1994.  By 1998 the Web had become an indispensable information resource. \n",
    "\n",
    "However, the problem of effectively searching the Web for relevant information was not well addressed.  A number of large search engines were available, with names that are now forgotten: Alta Vista, Lycos, Excite, and others. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "At present, most of them are no longer in existence, because Google emerged in 1998 and came to dominate Web search almost overnight.\n",
    "\n",
    "How did this happen?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "As background: a typical search engine uses a two-step process to retrieve pages related to a user’s query. \n",
    "\n",
    "In\n",
    "the first step, basic text processing is done to find all documents that contain the query terms. \n",
    "Due to the massive size of the Web, this first step can result in many thousands of retrieved pages related to the query.   \n",
    "\n",
    "Some of these pages are important, but most are not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The problem that Google solves better than the search engines of the mid 1990’s concerns the __ordering__ in which the resulting search results are presented.  This is the crucial factor in utility.  A user wants to find the \"correct\" or \"best\" item at the top of the search results.\n",
    "\n",
    "By displaying the most relevant pages at the top of the list returned each query, Google makes its search results very useful. The algorithm that gave Google this advantage is called PageRank."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__The Insight__\n",
    "\n",
    "Around 1998, the limitations of standard search engines, which just used term frequency, we becoming apparent.   A number of researchers were thinking about using additional sources of information to \"rate\" pages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The key idea that a number of researchers hit on was this: _links are endorsements._  \n",
    "\n",
    "When a first page contains a link to a second page, that is an indication that the author of the first page thinks the second page is worth looking at.  If the first and second pages both contain the same query terms, it is likely that the second page is an important page with respect to that query term."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Consider a set of web pages, for a single query term (say \"car manufacturers\") with this linking structure:\n",
    "\n",
    "<center>\n",
    "<img src=\"images/hub-authority.png\" alt=\"Hubs\" width=\"370\">\n",
    "\n",
    "It may be clear that the links between pages contain useful information.  But what is the best way to extract that information in the form of rankings?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Here is the strategy that Brin and Page used:\n",
    "\n",
    "From _“The PageRank citation ranking: Bringing order to the Web”_ (1998):\n",
    "> PageRank can be thought of as a model of user behavior. We assume there is a “random surfer” who is given a web page at random and keeps clicking on links, never hitting “back” but eventually gets bored and starts on another random page. The probability that the random surfer visits a page is its PageRank."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Today we'll study this algorithm, see how to implement it, and understand that what it is really about is Markov Chains and eigenvectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Random Walks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start with the notion of a __random walk.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "A random walk is a model of many sorts of processes that occur on graphs.\n",
    "\n",
    "Let us fix a graph $G$.  A random walk (sometimes called a \"drunkard's walk\") models the movement of an object on this graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We assume that the object moves from node to node in $G$, one move per time step $t.$  At time $t$ the object is at node $k$ (say) and at the next time $t+1$ it moves to another node chosen __at random__ from among the outgoing edges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "For our initial discussion, we will assume that $G$ is the line graph:\n",
    "\n",
    "<center>\n",
    "<img src=\"images/Lay-fig-10-3.jpg\" alt=\"Line Graph\" width=\"450\">\n",
    "\n",
    "This is a graph in which each node is connected to two neighbors.  It's natural to identify the nodes with the integers $k = 1,\\dots,n.$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "What happens at the endpoints of the graph (nodes 1 and $n$) must be specified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "One possibility is for the object to remain fixed at that location.   This is called a __random walk with absorbing boundaries.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Another possibility is for the object to bounce back one unit when an endpoint is reached.   This is called a __random walk with reflecting boundaries.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We can also set a particular probability $1-p$ of moving \"to the right\" (from $k$ to $k+1$) and $p$ of moving \"to the left\" (from $k$ to $k-1$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We can capture the process of movement on $G$ as a Markov Chain.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "As a reminder, recall these facts about a Markov Chain.\n",
    "\n",
    "For a Markov Chain having transition matrix $P$:\n",
    "\n",
    "* The largest eigenvalue of $P$ is 1.\n",
    "* If $P$ is regular, then \n",
    "    * There is only one eigenvalue equal to 1\n",
    "    * The chain will converge to the corresponding eigenvector as its _unique steady-state._\n",
    "* \"$P$ is regular\" means that for some $k>0$, all entries in $P^k$ are nonzero.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__Example.__  A random walk on $\\{1,2,3,4,5\\}$ with absorbing boundaries has a transition matrix of \n",
    "\n",
    "$$P=\\mat{{ccccc}1&p&0&0&0\\\\0&0&p&0&0\\\\0&1-p&0&p&0\\\\0&0&1-p&0&0\\\\0&0&0&1-p&1}$$\n",
    "\n",
    "<center>\n",
    "<img src=\"images/Lay-fig-10-3.jpg\" alt=\"Line Graph\" width=\"450\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "__Example.__ (\"Gambler's Ruin\").   Consider a very simple casino game.  A gambler (with some money to lose) flips a coin and calls heads or tails.  If the gambler is correct, she wins a dollar.  If she is wrong, she loses a dollar.  The gambler will quit the game when she has either won $n$ dollars or lost all of her money."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Suppose that $n=7$ and the gambler starts with \\$4.  The gambler's winnings must move up or down one dollar with each coin flip, and once the gambler's winnings reach 0 or 7, they do not change any more since the gambler has quit the game.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Such a process may be modeled as a random walk on $\\{0,1,2,3,4,5,6,7\\}$ with absorbing boundaries.   Since a move up or down is equally likely in this case, $p = 1/2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "This transition matrix is not regular, and there is not a single steady-state to which the chain surely converges.   \n",
    "\n",
    "However there are two steady-states, each corresponding to absorption at one boundary, and the chain will surely converge to one or the other.\n",
    "\n",
    "For example, if $p=0.45$, we find that the probability that the gambler will lose all her money to be $0.4$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"db35cbe6fcc90147\"></div>\n",
       "    <script type=\"text/javascript\">\n",
       "        $(function(){\n",
       "            var p = $(\"#db35cbe6fcc90147\");\n",
       "            if (p.length==0) return;\n",
       "\n",
       "            while (!p.hasClass(\"cell\")) {\n",
       "                p=p.parent();\n",
       "\n",
       "                if (p.prop(\"tagName\") ==\"body\") return;\n",
       "            }\n",
       "            var cell = p;\n",
       "            cell.find(\".input\").addClass(\"hide-in-slideshow\")\n",
       "        });\n",
       "    </script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sl.hide_code_in_slideshow()\n",
    "p = 0.45\n",
    "A = np.array([[1,p,0,0,0],[0,0,p,0,0],[0,1-p,0,p,0],[0,0,1-p,0,0],[0,0,0,1-p,1]])\n",
    "B = A.copy()\n",
    "for i in range(100):\n",
    "    B = A.dot(B)\n",
    "# print B.dot(np.array([0,0,1,0,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now let's consider a random walk on a more interesting graph:\n",
    "\n",
    "<img src=\"images/Lay-fig-10-4.jpg\" alt=\"Another Graph\" height=\"200\">\n",
    "\n",
    "Again, at each node there is an equal probability of departing to any adjacent node. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The transition matrix associated with a random walk on this graph is\n",
    "\n",
    "$$P = \\mat{{ccccccc}\n",
    "0&1/3&1/4&0&0&0&0\\\\\n",
    "1/2&0&1/4&0&1/2&0&0\\\\\n",
    "1/2&1/3&0&1&0&1/3&0\\\\\n",
    "0&0&1/4&0&0&0&0\\\\\n",
    "0&1/3&0&0&0&1/3&0\\\\\n",
    "0&0&1/4&0&1/2&0&1\\\\\n",
    "0&0&0&0&0&1/3&0}$$\n",
    "\n",
    "It turns out that this matrix is regular ($P^3$ has no zero entries.)\n",
    "\n",
    "Hence, the associated Markov Chain converges to a single steady state.  (It has only one eigenvalue of 1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The eigenvector corresponding to the eigenvalue of 1 is the steady-state of the Markov Chain.\n",
    "\n",
    "Hence we can find that the steady-state is $\\frac{1}{16}\\mat{{c}2\\\\3\\\\4\\\\1\\\\2\\\\3\\\\1}.$    \n",
    "\n",
    "That is, the probability of bring in node 1 at steady state is 2/16;  the probability of being in node 2 is 3/16;  the probability of being in node 3 is 4/16, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Notice anything?  (Look at $G$ again).\n",
    "\n",
    "<img src=\"images/Lay-fig-10-4.jpg\" alt=\"Another Graph\" height=\"200\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "It can be proved that the steady-state distribution of a random walk on an undirected graph is proportional to node degree. \n",
    "\n",
    "That is, the probability of being at a particular node at steady state is proportion to that node's degree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"813a4ebb177e3be4\"></div>\n",
       "    <script type=\"text/javascript\">\n",
       "        $(function(){\n",
       "            var p = $(\"#813a4ebb177e3be4\");\n",
       "            if (p.length==0) return;\n",
       "\n",
       "            while (!p.hasClass(\"cell\")) {\n",
       "                p=p.parent();\n",
       "\n",
       "                if (p.prop(\"tagName\") ==\"body\") return;\n",
       "            }\n",
       "            var cell = p;\n",
       "            cell.find(\".input\").addClass(\"hide-in-slideshow\")\n",
       "        });\n",
       "    </script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sl.hide_code_in_slideshow()\n",
    "A = np.array([\n",
    "[0,1./3,1./4,0,0,0,0],\n",
    "[1./2,0,1./4,0,1./2,0,0],\n",
    "[1./2,1./3,0,1,0,1./3,0],\n",
    "[0,0,1./4,0,0,0,0],\n",
    "[0,1./3,0,0,0,1./3,0],\n",
    "[0,0,1./4,0,1./2,0,1],\n",
    "[0,0,0,0,0,1./3,0]])\n",
    "w,v = np.linalg.eig(A)\n",
    "# print v[:,0]*(20./3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Another interesting object on which to walk randomly is a __directed__ graph.  In this graph, all edges are \"one-way streets\" -- nodes are joined not by lines but by arrows.   The chain can move from vertex to vertex, but only in the directions allowed by the arrows.\n",
    "\n",
    "An example of a directed graph is\n",
    "\n",
    "\n",
    "<img src=\"images/deeper-pagerank-fig.jpg\" alt=\"Directed Graph\" height=\"200\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The transition matrix for this graph is:\n",
    "\n",
    "$$P = \\mat{{cccccc}\n",
    "0&0&1/3&0&0&0\\\\\n",
    "1/2&0&1/3&0&0&0\\\\\n",
    "1/2&0&0&0&0&0\\\\\n",
    "0&0&0&0&1/2&1\\\\\n",
    "0&0&1/3&1/2&0&0\\\\\n",
    "0&0&0&1/2&1/2&0\n",
    "}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We can conclude that this matrix is __not__ regular.   Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "One reason we can conclude this is the column of zeros (column 2).  Any power of $A$ will preserve this column of zeros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## PageRank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many ways to make use of the link structure to infer which pages are most important to return at the top of the search results.  (There was a lot of experimentation in the late 1990s with various methods)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "A simple method is just to consider a page is \"important\" if many \"important\" pages link to it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "More precisely, this definition of \"importance\" is:\n",
    "\n",
    "$\\mbox{Importance of page $k$} = \\sum_j \\mbox{(Importance of page $j$)}\\cdot\\mbox{(Probability of going from page $j$ to page $k$.)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "This can be captured in terms of a random walk.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now we are ready to understand what Page and Brin were saying in 1998:\n",
    "\n",
    "> PageRank can be thought of as a model of user behavior. We assume there is a “random surfer” who is given a web page at random and keeps clicking on links, never hitting “back” but eventually gets bored and starts on another random page. The probability that the random surfer visits a page is its PageRank."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Intuitively, the a random surfer should spend more time at \"important\" pages and less time at unimportant pages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The way to interpret this precisely is:\n",
    "\n",
    "1) Form the graph that encodes the connections between Web pages that are retrieved for a particular query. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "2) Construct a Markov chain that corresponds to a random walk on this graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "3) Rank-order the pages according to their probability in the Markov chain's steady state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "So let's try to make this work and see what happens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__Example.__   Assume a set of Web pages have been selected based on a text query, eg, pages related to \"personal 737 jets.\"\n",
    "\n",
    "These pages have various links between them, as represented by this graph:\n",
    "\n",
    "<img src=\"images/deeper-pagerank-fig.jpg\" alt=\"Directed Graph\" height=\"200\">\n",
    "\n",
    "Construct the unique steady-state distribution for a random walk on this graph, if it exists.  That is, construct the PageRank for this set of Web pages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "__Solution.__\n",
    "\n",
    "The key question we must ask is __whether a unique steady state exists.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "__Step 1.__  \n",
    "\n",
    "Assume there are $n$ pages to be ranked.  Construct an $n\\times n$ transition matrix for the Markov chain.\n",
    "\n",
    "Set the Markov chain transitions so that each outgoing link from a node has equal probability of being taken."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We have already seen the transition matrix for this graph:\n",
    "\n",
    "$$P = \\mat{{cccccc}\n",
    "0&0&1/3&0&0&0\\\\\n",
    "1/2&0&1/3&0&0&0\\\\\n",
    "1/2&0&0&0&0&0\\\\\n",
    "0&0&0&0&1/2&1\\\\\n",
    "0&0&1/3&1/2&0&0\\\\\n",
    "0&0&0&1/2&1/2&0\n",
    "}$$\n",
    "\n",
    "We have observed that this transition matrix is __not__ regular, because for any $A^k, k>0,$ the second column will  be zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "To address this, let's ask why it happens.   \n",
    "\n",
    "The reason that column 2 of $P$ is zero is that the Web page corresponding to node 2 has no links embedded in it, so there is nowhere to go from this page.   Of course this will happen a lot in an arbitrary collection of Web pages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Note that Page and Brin say that the random surfer will occasionally \"start on another random page.\"   In other words, it seems reasonable that when reaching a page with no embedded links, the surfer chooses another page at random.\n",
    "\n",
    "So this motivates the first adjustment to $P$:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__Step 2:__\n",
    "\n",
    "Form the matrix $P'$ as follows:  for each column in $P$ that is entirely zeros, replace it with a column in which each entry is $1/n$.\n",
    "\n",
    "In our example:\n",
    "\n",
    "$$P = \\mat{{cccccc}\n",
    "0&0&1/3&0&0&0\\\\\n",
    "1/2&0&1/3&0&0&0\\\\\n",
    "1/2&0&0&0&0&0\\\\\n",
    "0&0&0&0&1/2&1\\\\\n",
    "0&0&1/3&1/2&0&0\\\\\n",
    "0&0&0&1/2&1/2&0\n",
    "} \\;\\;{\\Huge \\rightarrow}\\;\\;\n",
    "P' = \\mat{{cccccc}\n",
    "0&1/n&1/3&0&0&0\\\\\n",
    "1/2&1/n&1/3&0&0&0\\\\\n",
    "1/2&1/n&0&0&0&0\\\\\n",
    "0&1/n&0&0&1/2&1\\\\\n",
    "0&1/n&1/3&1/2&0&0\\\\\n",
    "0&1/n&0&1/2&1/2&0\n",
    "}\\;\\;=\\;\\;\n",
    " \\mat{{cccccc}\n",
    "0&1/6&1/3&0&0&0\\\\\n",
    "1/2&1/6&1/3&0&0&0\\\\\n",
    "1/2&1/6&0&0&0&0\\\\\n",
    "0&1/6&0&0&1/2&1\\\\\n",
    "0&1/6&1/3&1/2&0&0\\\\\n",
    "0&1/6&0&1/2&1/2&0\n",
    "}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Nonetheless, even after this change, $P'$ can fail to be regular.\n",
    "\n",
    "In other words, for an arbitrary set of web pages, there is no guarantee that their transition matrix will be regular."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Once again, let's read the words of Page and Brin closely: the surfer \"eventually gets bored and starts on another random page.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__Step 3.__\n",
    "\n",
    "In practice this means that there a small probability that the surfer will jump from any page to any other page at random.\n",
    "\n",
    "Let's call this small probability $\\alpha.$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We can't just add $\\alpha$ to every entry in $P'$, because then the columns of the new matrix would not sum to 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Instead we decrease each entry in $P'$ by a factor of $(1-\\alpha)$, and then add ${\\alpha}/{n}$ to it.\n",
    "\n",
    "So we compute the final transition matrix $P''$ as:\n",
    "\n",
    "$$P''_{ij} = (1-\\alpha)P'_{ij} + \\frac{\\alpha}{n}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We can write this as a matrix equation:\n",
    "\n",
    "$$P'' = (1-\\alpha)P' + \\frac{\\alpha}{n} \\mathbf{1}$$\n",
    "\n",
    "where $\\mathbf{1}$ is an $n\\times n$ matrix of 1's."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In our example, let's say that $\\alpha = 10$ (in reality it would be smaller).  So $\\alpha/n = 1/60.$\n",
    "\n",
    "Then:\n",
    "\n",
    "$$ P' \\mat{{cccccc}\n",
    "0&1/6&1/3&0&0&0\\\\\n",
    "1/2&1/6&1/3&0&0&0\\\\\n",
    "1/2&1/6&0&0&0&0\\\\\n",
    "0&1/6&0&0&1/2&1\\\\\n",
    "0&1/6&1/3&1/2&0&0\\\\\n",
    "0&1/6&0&1/2&1/2&0\n",
    "} \\;\\;{\\Huge\\rightarrow}\\;\\; P'' = \\mat{{cccccc}\n",
    "1/60&1/6&19/60&1/60&1/60&1/60\\\\\n",
    "7/15&1/6&19/60&1/60&1/60&1/60\\\\\n",
    "7/15&1/6&1/60&1/60&1/60&1/60\\\\\n",
    "1/60&1/6&1/60&1/60&7/15&11/12\\\\\n",
    "1/60&1/6&19/20&7/15&1/60&1/60\\\\\n",
    "1/60&1/6&1/60&7/15&7/15&1/60\n",
    "}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Obviously, $P''$ is regular, because all its entries are positive (they are at least $\\alpha/n.$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$P''$ is the Markov Chain that Brin and Page defined, and which is used by PageRank to rank pages in response to a Google search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "__Step 4.__  Compute the steady-state of $P''$, and rank pages according to their magnitude in the resulting vector.\n",
    "\n",
    "We can do this by solving $P''\\vx = \\vx$, or we can compute the eigenvectors of $P''$ and use the eigenvector that corresponds to $\\lambda = 1.$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "For the example $P''$, we find that the steady-state vector is:\n",
    "\n",
    "$\\vx = \\mat{{r}0.071\\\\0.104\\\\0.080\\\\0.720\\\\0.395\\\\0.549}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "So the final ranking of pages is: 4, 6, 5, 2, 3, 1.\n",
    "\n",
    "This is the order that PageRank would display its results, with page 4 at the top of the list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's see how to do __Step 4__ in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.          0.61008601 -0.08958752 -0.37049849 -0.44999999 -0.45000001]\n"
     ]
    }
   ],
   "source": [
    "# Here is the P'' matrix as compute in steps 1 through 3.\n",
    "P = np.array([\n",
    "[1./60, 1./6, 19./60, 1./60, 1./60,  1./60],\n",
    "[7./15, 1./6, 19./60, 1./60, 1./60,  1./60],\n",
    "[7./15, 1./6,  1./60, 1./60, 1./60,  1./60],\n",
    "[1./60, 1./6,  1./60, 1./60, 7./15, 11./12],\n",
    "[1./60, 1./6, 19./60, 7./15, 1./60,  1./60],\n",
    "[1./60, 1./6,  1./60, 7./15, 7./15,  1./60]\n",
    "])\n",
    "eigenvalues, eigenvectors = np.linalg.eig(P)\n",
    "print eigenvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# find the location of the largest eigenvalue (1), \n",
    "# by computing the indices that would sort the eigenvalues\n",
    "# from smallest to largest\n",
    "indices = np.argsort(eigenvalues)\n",
    "# and take the index of the largest eigenvalue\n",
    "principal = indices[-1]\n",
    "print principal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.07147212  0.10363458  0.07971891  0.72040867  0.39565602  0.54978556]\n"
     ]
    }
   ],
   "source": [
    "# using the index of the largest eigenvalue, extract\n",
    "# the corresponding eigenvector (the steady state vector)\n",
    "steadyState = eigenvectors[:,principal]\n",
    "print steadyState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 2 1 4 5 3]\n"
     ]
    }
   ],
   "source": [
    "# find the order of the pages in the steady state vector\n",
    "# this function sorts from smallest to largest (reverse of what we want)\n",
    "reverseOrder = np.argsort(steadyState)\n",
    "print reverseOrder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final order = [4 6 5 2 3 1]\n",
      "importance = [ 0.72040867  0.54978556  0.39565602  0.10363458  0.07971891  0.07147212]\n"
     ]
    }
   ],
   "source": [
    "# reverse the order to get the most important page first\n",
    "# and add one to convert from zero indexing to indexing of example\n",
    "order = 1 + reverseOrder[::-1]\n",
    "print 'final order = {}'.format(order)\n",
    "print 'importance = {}'.format(steadyState[order-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<img src=\"images/deeper-pagerank-fig.jpg\" alt=\"Directed Graph\" height=\"200\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Computing PageRank: the Power Method\n",
    "\n",
    "From a mathematical standpoint, we are done.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "However, from a Computer Science standpoint, there are still some issues. &#9786;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The most significant issue is simply this: PageRank results must be provided __very quickly.__   Search engines are in competition and speed is a competitive advantage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Here is an example Google search:\n",
    "\n",
    "<img src=\"images/sample-google-search.jpg\" alt=\"Directed Graph\" height=\"350\" style=\"border:5px solid black\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Notice that the search returned about 400,000 results!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Recall that using Gaussian elimination to solve $A\\vx = \\vb$ takes about $\\frac{2}{3}n^3$ operations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In this case, apparently $n = 400,000.$  \n",
    "\n",
    "So computing the PageRank in the straightforward way we've described would take about 42,667,000,000,000,000 operations.  \n",
    "\n",
    "Assuming a 2GHz CPU, that's on the order of __eight months.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.23045267489712"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((2./3)*(400000**3))/((2*10**9)*(3600*24*30))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need a faster way to compute the PageRank!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an important point: we only need the __principal__ eigenvector. (The one corresponding to $\\lambda = 1$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's review how a Markov chain gets to steady state.  As we discussed at the end of the lecture on the characteristic equation, the state of the chain at any point is given by\n",
    "\n",
    "$${\\bf x_k} = c_1{\\bf v_1}\\lambda_1^k + c_2{\\bf v_2}\\lambda_2^k + \\dots + c_n{\\bf v_n}\\lambda_n^k.$$\n",
    "\n",
    "Let's assume that $\\lambda_1$ is the eigenvalue 1.  If the chain converges to steady sate, then we know that all eigenvalues other than $\\lambda_1$ are less than 1.\n",
    "\n",
    "So:\n",
    "\n",
    "$$\\lim_{k\\rightarrow\\infty}{\\bf x_k} = c_1{\\bf v_1}.$$\n",
    "\n",
    "Note that $c_1$ is just a constant that doesn't affect the relative sizes of the components of ${\\vx_k}$ in the limit of large $k.$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
